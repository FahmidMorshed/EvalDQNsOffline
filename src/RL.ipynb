{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T19:02:46.508621Z",
     "start_time": "2020-10-26T19:02:42.055447Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fahmid/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/fahmid/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/fahmid/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/fahmid/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/fahmid/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/fahmid/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/fahmid/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/fahmid/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/fahmid/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/fahmid/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/fahmid/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/fahmid/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import pdb\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import time\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "import keras.layers as layers\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import ast\n",
    "import gym\n",
    "\n",
    "random_state=0\n",
    "np.random.seed(random_state)\n",
    "random.seed(random_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T02:55:41.481932Z",
     "start_time": "2020-10-27T02:55:41.445074Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, df_batch, state_size, action_size, \n",
    "                 minibatch_size=64, gamma=.9, lr=0.0001, units=128,\n",
    "                 vanilla=True, dueling=False, double_param=0, priority_alpha = 0,\n",
    "                 copy_online_to_target_ep=100, eval_after=100):\n",
    "        \n",
    "        # NOT FOR NOW. FUTURE WORK\n",
    "        #adding priority as noise in batch\n",
    "        df_batch.at[:, 'weight'] = 0.0\n",
    "        for i, row in df_batch.iterrows():\n",
    "            df_batch.at[i, 'priority'] = (row['reward'] + np.random.uniform(0, 0.001))**priority_alpha\n",
    "        \n",
    "        \n",
    "        # setting parameters\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.batch = df_batch\n",
    "        \n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.gamma = gamma\n",
    "        self.learning_rate = lr\n",
    "        self.units = units\n",
    "        \n",
    "        self.vanilla = vanilla\n",
    "        self.dueling = dueling\n",
    "        self.double_param = double_param\n",
    "        self.priority_alpha = priority_alpha\n",
    "        \n",
    "        self.copy_online_to_target_ep = copy_online_to_target_ep\n",
    "        self.eval_after = eval_after\n",
    "        \n",
    "        \n",
    "        # setting up the models\n",
    "        if self.dueling:\n",
    "            # TODO\n",
    "            self.model_1 = self._build_model_dueling()\n",
    "            self.model_2 = self._build_model_dueling()\n",
    "        else:\n",
    "            self.model_1 = self._build_model()\n",
    "            self.model_2 = self._build_model()\n",
    "        \n",
    "        # evaluation variables\n",
    "        self.R = []\n",
    "        self.ecrs = []\n",
    "        \n",
    "        \n",
    "    def _build_model(self):\n",
    "        \"\"\"\n",
    "        Standard DQN model\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        \n",
    "        \n",
    "        model.add(layers.Dense(self.units, activation='relu', kernel_initializer='glorot_normal'))\n",
    "        model.add(layers.Dense(self.units, activation='relu', kernel_initializer='glorot_normal'))\n",
    "        \n",
    "#         model.add(layers.Dense(self.action_size, activation='linear', kernel_initializer='glorot_normal'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate), metrics=[tf.keras.metrics.RootMeanSquaredError(), 'mae'])\n",
    "        return model\n",
    "    \n",
    "    def act(self, state):\n",
    "        state_array = np.array(state.reshape(1, self.state_size))\n",
    "        act_values = self.model_2.predict(state_array)\n",
    "        return np.argmax(act_values[0]), np.max(act_values[0])\n",
    "    \n",
    "    def learn(self, epoch, env=None):\n",
    "        for i in range(epoch):\n",
    "            self._learn_minibatch()\n",
    "            \n",
    "            if (i+1)%self.copy_online_to_target_ep==0:\n",
    "                self.model_2 = self.model_1\n",
    "            \n",
    "            if (i+1)%self.eval_after==0:\n",
    "                r = self.run_env(env)\n",
    "                self.R.append(r)\n",
    "                ecr = 0\n",
    "#                 t1 = time.time()\n",
    "#                 ecr = self.ecr_reward()\n",
    "#                 t2 = time.time()\n",
    "#                 print(\"ecr time\", t2-t1)\n",
    "                print(\"--epoch: {}/{} | ECR: {:.5f} | R: {:.2f} --\".format(i+1, epoch, ecr, r))\n",
    "        \n",
    "        self.model_2 = self.model_1\n",
    "        r = self.run_env(env)\n",
    "        self.R.append(r)\n",
    "\n",
    "        ecr = self.ecr_reward()\n",
    "        print(\"--final run--\")\n",
    "        print(\"--epoch: {}/{} | ECR: {:.5f} | R: {:.2f} --\".format(i+1, epoch, ecr, r))\n",
    "    \n",
    "    \n",
    "    def _learn_minibatch(self):\n",
    "        priority_sum = self.batch['priority'].sum()\n",
    "        self.batch['weight'] = self.batch['priority']/priority_sum\n",
    "        \n",
    "        \n",
    "        minibatch = self.batch.sample(self.minibatch_size, weights=self.batch['weight'])\n",
    "        for i, row in minibatch.iterrows():\n",
    "            \n",
    "            state, action, reward, next_state, done = row['state'], row['action'], row['reward'], row['next_state'], row['done']\n",
    "            \n",
    "            target_q = reward\n",
    "            \n",
    "              \n",
    "            if self.vanilla:\n",
    "                if not done: \n",
    "                    ns_act_values = self.model_1.predict(next_state.reshape(1,self.state_size))[0]\n",
    "                    a_prime = np.argmax(ns_act_values)\n",
    "\n",
    "                    target_ns_act_values = self.model_2.predict(next_state.reshape(1,self.state_size))[0]\n",
    "                    target_ns_q = target_ns_act_values[a_prime]\n",
    "\n",
    "                    target_q = reward + self.gamma*target_ns_q\n",
    "\n",
    "                    self.batch.at[i, 'pred_action'] = a_prime\n",
    "                    self.batch.at[i, 'pred_reward'] = target_q\n",
    "                \n",
    "                target_f = self.model_1.predict(state.reshape(1,self.state_size))\n",
    "                # Prioritized Experience Reply with noise\n",
    "                self.batch.loc[i, 'priority'] = (abs(target_q - target_f[0][action]) + np.random.uniform(0, 0.001))**self.priority_alpha\n",
    "\n",
    "\n",
    "                target_f[0][action] = target_q\n",
    "                if not done:\n",
    "                    self.model_1.fit(state.reshape(1,self.state_size), target_f, epochs=1, verbose=0)\n",
    "                else:\n",
    "                    self.model_1.fit(state.reshape(1,self.state_size), target_f, epochs=10, verbose=0)\n",
    "            \n",
    "                \n",
    "        \n",
    "        \n",
    "            \n",
    "    def volatile(self, random_batch):\n",
    "        random_batch = self.batch.loc[~self.batch['pred_reward'].isnull()].sample(100, replace=True)\n",
    "        total_v = 0\n",
    "        for i, row in random_batch.iterrows():\n",
    "            state, action, reward, next_state, done, old_q = row['state'], row['action'], row['reward'], row['next_state'], row['done'], row['pred_reward']\n",
    "            \n",
    "            target_f = self.model_1.predict(state.reshape(1,self.state_size))\n",
    "            pred_q = target_f[0][action]\n",
    "            \n",
    "            total_v += (pred_q - old_q)\n",
    "        total_v = total_v/100\n",
    "        return total_v\n",
    "            \n",
    "    def ecr_reward(self):\n",
    "        self.predict(self.batch)\n",
    "        reward = 0.0\n",
    "        count = 0\n",
    "        for i, row in self.batch.loc[self.batch['transition_id']==1].iterrows():\n",
    "            state = row['state']\n",
    "            next_state = row['next_state']\n",
    "                \n",
    "            reward += self.act(state)[1]\n",
    "            count += 1\n",
    "            \n",
    "        ecr = reward/count\n",
    "        self.ecrs.append(ecr)\n",
    "        return ecr\n",
    "    \n",
    "    def predict(self, df):\n",
    "        df['pred_action'] = -1\n",
    "        df['pred_reward'] = -1\n",
    "        for i, row in df.iterrows():\n",
    "            state = row['state']\n",
    "            next_state = row['next_state']\n",
    "            \n",
    "            act, q = self.act(state)\n",
    "            df.loc[i, 'pred_action'] = act\n",
    "            df.loc[i, 'pred_reward'] = q\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def run_env(self, env):\n",
    "        if env is None:\n",
    "            return 0\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        while True:\n",
    "            action = self.act(state)[0]\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            if done:\n",
    "                state = env.reset()\n",
    "                return total_reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T02:42:45.888173Z",
     "start_time": "2020-10-27T02:41:53.552653Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cartpole | Total transitions: 222307  | Total episodes: 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_id</th>\n",
       "      <th>transition_id</th>\n",
       "      <th>state</th>\n",
       "      <th>action</th>\n",
       "      <th>immediate_reward</th>\n",
       "      <th>delayed_reward</th>\n",
       "      <th>done</th>\n",
       "      <th>next_state</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.022543404416445246, 0.03232884247292103, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.021896827566986826, -0.16306397071080267, ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.021896827566986826, -0.16306397071080267, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.02515810698120288, 0.03176435710102907, 0....</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.02515810698120288, 0.03176435710102907, 0....</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.024522819839182298, 0.2264861821961012, 0....</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.024522819839182298, 0.2264861821961012, 0....</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.019993096195260275, 0.42119080133853226, 0...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.019993096195260275, 0.42119080133853226, 0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.01156928016848963, 0.615967181288758, 0.01...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222302</th>\n",
       "      <td>10000</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.029725992124671002, 0.6073723062537161, -0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.01757854599959668, 0.8032876496052292, -0....</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222303</th>\n",
       "      <td>10000</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.01757854599959668, 0.8032876496052292, -0....</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.0015127930074920956, 0.9993581291554666, -...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222304</th>\n",
       "      <td>10000</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.0015127930074920956, 0.9993581291554666, -...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.01847436957561724, 1.195582202625824, -0.13...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222305</th>\n",
       "      <td>10000</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.01847436957561724, 1.195582202625824, -0.13...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.04238601362813372, 1.3919096434474165, -0.1...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222306</th>\n",
       "      <td>10000</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.07022420649708205, 1.58822559995714, -0.219...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.07022420649708205, 1.58822559995714, -0.219...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222307 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        episode_id  transition_id  \\\n",
       "0                1              0   \n",
       "1                1              1   \n",
       "2                1              2   \n",
       "3                1              3   \n",
       "4                1              4   \n",
       "...            ...            ...   \n",
       "222302       10000              3   \n",
       "222303       10000              4   \n",
       "222304       10000              5   \n",
       "222305       10000              6   \n",
       "222306       10000              7   \n",
       "\n",
       "                                                    state  action  \\\n",
       "0       [-0.022543404416445246, 0.03232884247292103, 0...       0   \n",
       "1       [-0.021896827566986826, -0.16306397071080267, ...       1   \n",
       "2       [-0.02515810698120288, 0.03176435710102907, 0....       1   \n",
       "3       [-0.024522819839182298, 0.2264861821961012, 0....       1   \n",
       "4       [-0.019993096195260275, 0.42119080133853226, 0...       1   \n",
       "...                                                   ...     ...   \n",
       "222302  [-0.029725992124671002, 0.6073723062537161, -0...       1   \n",
       "222303  [-0.01757854599959668, 0.8032876496052292, -0....       1   \n",
       "222304  [-0.0015127930074920956, 0.9993581291554666, -...       1   \n",
       "222305  [0.01847436957561724, 1.195582202625824, -0.13...       1   \n",
       "222306  [0.07022420649708205, 1.58822559995714, -0.219...       1   \n",
       "\n",
       "        immediate_reward  delayed_reward   done  \\\n",
       "0                    1.0             0.0  False   \n",
       "1                    1.0             0.0  False   \n",
       "2                    1.0             0.0  False   \n",
       "3                    1.0             0.0  False   \n",
       "4                    1.0             0.0  False   \n",
       "...                  ...             ...    ...   \n",
       "222302               1.0             0.0  False   \n",
       "222303               1.0             0.0  False   \n",
       "222304               1.0             0.0  False   \n",
       "222305               1.0             0.0  False   \n",
       "222306              -1.0             6.0   True   \n",
       "\n",
       "                                               next_state info  \n",
       "0       [-0.021896827566986826, -0.16306397071080267, ...   {}  \n",
       "1       [-0.02515810698120288, 0.03176435710102907, 0....   {}  \n",
       "2       [-0.024522819839182298, 0.2264861821961012, 0....   {}  \n",
       "3       [-0.019993096195260275, 0.42119080133853226, 0...   {}  \n",
       "4       [-0.01156928016848963, 0.615967181288758, 0.01...   {}  \n",
       "...                                                   ...  ...  \n",
       "222302  [-0.01757854599959668, 0.8032876496052292, -0....   {}  \n",
       "222303  [-0.0015127930074920956, 0.9993581291554666, -...   {}  \n",
       "222304  [0.01847436957561724, 1.195582202625824, -0.13...   {}  \n",
       "222305  [0.04238601362813372, 1.3919096434474165, -0.1...   {}  \n",
       "222306  [0.07022420649708205, 1.58822559995714, -0.219...   {}  \n",
       "\n",
       "[222307 rows x 9 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOME FORMATTING ISSUES WITH CSV\n",
    "df = pd.read_csv('../data/CartPole-v1_10k.csv')\n",
    "for i, row in df.iterrows():\n",
    "    state = ast.literal_eval(row['state'])\n",
    "    df.at[i, 'state'] = np.array(state)\n",
    "    \n",
    "    next_state = ast.literal_eval(row['next_state'])\n",
    "    df.at[i, 'next_state'] = np.array(next_state)\n",
    "\n",
    "dlt_lst = []\n",
    "for i, row in df.iterrows():\n",
    "    if row['done']==True and row['delayed_reward']==0:\n",
    "        dlt_lst.append(i)\n",
    "len(dlt_lst)    \n",
    "\n",
    "df.drop(dlt_lst, inplace=True)\n",
    "df = df.sort_values(by=['episode_id', 'transition_id'])\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df\n",
    "\n",
    "print(\"Cartpole\", \"| Total transitions:\", len(df), \" | Total episodes:\", len(df['episode_id'].unique()))\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:58:29.404624Z",
     "start_time": "2020-10-27T02:55:43.843073Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--epoch: 100/5000 | ECR: 0.00000 | R: 9.00 --\n",
      "--epoch: 200/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 300/5000 | ECR: 0.00000 | R: 15.00 --\n",
      "--epoch: 400/5000 | ECR: 0.00000 | R: 13.00 --\n",
      "--epoch: 500/5000 | ECR: 0.00000 | R: 66.00 --\n",
      "--epoch: 600/5000 | ECR: 0.00000 | R: 195.00 --\n",
      "--epoch: 700/5000 | ECR: 0.00000 | R: 9.00 --\n",
      "--epoch: 800/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 900/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 1000/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 1100/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 1200/5000 | ECR: 0.00000 | R: 93.00 --\n",
      "--epoch: 1300/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 1400/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 1500/5000 | ECR: 0.00000 | R: 9.00 --\n",
      "--epoch: 1600/5000 | ECR: 0.00000 | R: 8.00 --\n",
      "--epoch: 1700/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 1800/5000 | ECR: 0.00000 | R: 9.00 --\n",
      "--epoch: 1900/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 2000/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 2100/5000 | ECR: 0.00000 | R: 9.00 --\n",
      "--epoch: 2200/5000 | ECR: 0.00000 | R: 11.00 --\n",
      "--epoch: 2300/5000 | ECR: 0.00000 | R: 25.00 --\n",
      "--epoch: 2400/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 2500/5000 | ECR: 0.00000 | R: 9.00 --\n",
      "--epoch: 2600/5000 | ECR: 0.00000 | R: 9.00 --\n",
      "--epoch: 2700/5000 | ECR: 0.00000 | R: 78.00 --\n",
      "--epoch: 2800/5000 | ECR: 0.00000 | R: 9.00 --\n",
      "--epoch: 2900/5000 | ECR: 0.00000 | R: 9.00 --\n",
      "--epoch: 3000/5000 | ECR: 0.00000 | R: 8.00 --\n",
      "--epoch: 3100/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 3200/5000 | ECR: 0.00000 | R: 9.00 --\n",
      "--epoch: 3300/5000 | ECR: 0.00000 | R: 20.00 --\n",
      "--epoch: 3400/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 3500/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 3600/5000 | ECR: 0.00000 | R: 9.00 --\n",
      "--epoch: 3700/5000 | ECR: 0.00000 | R: 9.00 --\n",
      "--epoch: 3800/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 3900/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 4000/5000 | ECR: 0.00000 | R: 25.00 --\n",
      "--epoch: 4100/5000 | ECR: 0.00000 | R: 11.00 --\n",
      "--epoch: 4200/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 4300/5000 | ECR: 0.00000 | R: 8.00 --\n",
      "--epoch: 4400/5000 | ECR: 0.00000 | R: 13.00 --\n",
      "--epoch: 4500/5000 | ECR: 0.00000 | R: 12.00 --\n",
      "--epoch: 4600/5000 | ECR: 0.00000 | R: 9.00 --\n",
      "--epoch: 4700/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--epoch: 4800/5000 | ECR: 0.00000 | R: 45.00 --\n",
      "--epoch: 4900/5000 | ECR: 0.00000 | R: 9.00 --\n",
      "--epoch: 5000/5000 | ECR: 0.00000 | R: 10.00 --\n",
      "--final run--\n",
      "--epoch: 5000/5000 | ECR: 8.93996 | R: 8.00 --\n"
     ]
    }
   ],
   "source": [
    "df['reward'] = df['delayed_reward']\n",
    "epoch = 5000\n",
    "agent = DQNAgent(df_batch=df, state_size=len(df.iloc[0]['state']), action_size=2, \n",
    "                 vanilla=True, dueling=False, double_param=0, priority_alpha=0.05,\n",
    "                 copy_online_to_target_ep=100, eval_after=100)\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "agent.learn(epoch, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T02:37:45.914278Z",
     "start_time": "2020-10-27T02:37:45.203431Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
